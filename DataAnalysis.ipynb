{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imp\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from HelperClass.DataProcessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataFile = 'Data/train.csv'\n",
    "testDataFile = 'Data/test.csv'\n",
    "dataTypes = {\n",
    "    'PassengerId' : 'int64',\n",
    "    'Survived' : 'int64',\n",
    "    'Pclass' : 'int64',\n",
    "    'Name' : 'object',\n",
    "    'Sex' : 'object',\n",
    "    'Age' : 'float64',\n",
    "    'SibSp' : 'int64',\n",
    "    'Parch' : 'int64',\n",
    "    'Ticket' : 'object',\n",
    "    'Fare' : 'float64',\n",
    "    'Cabin' : 'object',\n",
    "    'Embarked' : 'object'\n",
    "}\n",
    "sep = ','\n",
    "target = 'Survived'\n",
    "randomSeed = 83213\n",
    "testRatio = 0.20\n",
    "numCores = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataProc = DataProcessing(trainDataFile, dataTypes, sep)\n",
    "dataProc.ReadFile()\n",
    "dataProc.AllData = dataProc.AllData[~dataProc.AllData.Embarked.isnull()]\n",
    "\n",
    "submitDataProc = DataProcessing(testDataFile, dataTypes, sep)\n",
    "submitDataProc.ReadFile()\n",
    "submitDataProc.AllData = submitDataProc.AllData[~submitDataProc.AllData.Embarked.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Findings\n",
    "1. Age makes difference, F_onewayResult(statistic=4.271194933815904, pvalue=0.03912465401348333)\n",
    "2. Fare makes difference, F_onewayResult(statistic=63.03076422804448, pvalue=6.120189341921873e-15)\n",
    "3. PassengerId doesn't make difference, F_onewayResult(statistic=0.022284812266068058, pvalue=0.8813657768798144)\n",
    "4. Pclass makes difference, F_onewayResult(statistic=115.03127218827665, pvalue=2.5370473879805644e-25)\n",
    "5. SibSp doesn't make difference, F_onewayResult(statistic=1.110572204113227, pvalue=0.29224392869817906)\n",
    "6. Parch makes difference, F_onewayResult(statistic=5.963463836603541, pvalue=0.0147992453747224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PopulateFeatures(data):\n",
    "    data.Cabin.fillna('NA', inplace=True)\n",
    "    data['CabinType'] = data.Cabin.fillna('NA').str.get(0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataProc.AllData = PopulateFeatures(dataProc.AllData)\n",
    "submitDataProc.AllData = PopulateFeatures(submitDataProc.AllData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataProc.AllData['CabinType_B_D_E'] = np.where(dataProc.AllData.CabinType.isin(['B', 'D', 'E']), 2, 1)\n",
    "submitDataProc.AllData['CabinType_B_D_E'] = np.where(submitDataProc.AllData.CabinType.isin(['B', 'D', 'E']), 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataProc.AllData.Age.fillna(-999, inplace=True)\n",
    "submitDataProc.AllData.Age.fillna(-999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [-10000, 0, 20, 60, 1000]\n",
    "dataProc.AllData['AgeGroup'] = pd.cut(dataProc.AllData.Age, bins).astype(str)\n",
    "submitDataProc.AllData['AgeGroup'] = pd.cut(submitDataProc.AllData.Age, bins).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataProc.AllData['GenderAgeGroup'] = dataProc.AllData.Sex + '_' + dataProc.AllData.AgeGroup\n",
    "submitDataProc.AllData['GenderAgeGroup'] = submitDataProc.AllData.Sex + '_' + submitDataProc.AllData.AgeGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GenderAgeGroup</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female_(60, 1000]</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_(20, 60]</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_(0, 20]</th>\n",
       "      <td>0.688312</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_(-10000, 0]</th>\n",
       "      <td>0.679245</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_(0, 20]</th>\n",
       "      <td>0.284314</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_(20, 60]</th>\n",
       "      <td>0.186747</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_(-10000, 0]</th>\n",
       "      <td>0.129032</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_(60, 1000]</th>\n",
       "      <td>0.105263</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Survived      \n",
       "                        mean count\n",
       "GenderAgeGroup                    \n",
       "female_(60, 1000]   1.000000     2\n",
       "female_(20, 60]     0.777778   180\n",
       "female_(0, 20]      0.688312    77\n",
       "female_(-10000, 0]  0.679245    53\n",
       "male_(0, 20]        0.284314   102\n",
       "male_(20, 60]       0.186747   332\n",
       "male_(-10000, 0]    0.129032   124\n",
       "male_(60, 1000]     0.105263    19"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataProc.AllData.groupby(['GenderAgeGroup']).agg({'Survived' : ['mean', 'count']}).sort_values(by=('Survived', 'mean'), \n",
    "                                                                                               ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "genderAgeGroups = {\n",
    "    'GenderAgeGroup' : {\n",
    "        'female_(20, 60]' : 7, \n",
    "        'female_(60, 1000]' : 8,\n",
    "        'female_(0, 20]' : 6, \n",
    "        'female_(-10000, 0]' : 5,\n",
    "        'male_(0, 20]' : 4, \n",
    "        'male_(20, 60]' : 3, \n",
    "        'male_(-10000, 0]' : 2, \n",
    "        'male_(60, 1000]' : 1\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataProc.AllData.replace(genderAgeGroups, inplace=True)\n",
    "submitDataProc.AllData.replace(genderAgeGroups, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataProc.AllData['Sex'] = np.where(dataProc.AllData['Sex'] == 'male', 1, 2)\n",
    "submitDataProc.AllData['Sex'] = np.where(submitDataProc.AllData['Sex'] == 'male', 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embarkedEncoding = {\n",
    "    'Embarked' : {\n",
    "       'S' : 1,\n",
    "       'Q' : 1,\n",
    "       'C' : 2\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataProc.AllData.replace(embarkedEncoding, inplace=True)\n",
    "submitDataProc.AllData.replace(embarkedEncoding, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "numCols = ['Fare', 'Pclass', 'Parch', 'CabinType_B_D_E', 'GenderAgeGroup', 'Embarked', 'Sex']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ageFilledInData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataProc.AllData['Ticket_Num_Ind'] = dataProc.AllData['Ticket'].str.isnumeric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataProc.PopulateFeatureColumns(numCols)\n",
    "submitDataProc.PopulateFeatureColumns(numCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataProc.PopulateFeatureAndLabel(target)\n",
    "submitDataProc.X = submitDataProc.AllData[numCols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataProc.RandomSplitTrainTestData(testRatio, randomSeed, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "averageFareThridClass = submitDataProc.AllData[(submitDataProc.AllData.Pclass == 3) & \n",
    "                                               (submitDataProc.AllData.CabinType == 'N')].Fare.mean()\n",
    "submitDataProc.X.Fare.fillna(averageFareThridClass, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedCols = ['CabinType_B_D_E', 'Embarked', 'Fare', 'GenderAgeGroup', 'Parch', 'Pclass', 'Sex']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "preProc = ColumnTransformer([\n",
    "    #('StdScaler', StandardScaler(), numCols),\n",
    "    #('OneHot', OneHotEncoder(handle_unknown='ignore'), catCols)\n",
    "])\n",
    "rf = RandomForestClassifier(random_state = randomSeed)\n",
    "rfpipeline = Pipeline([#('preProcessing', preProc),\n",
    "                       #('ReduceDim', SelectKBest(f_classif)),\n",
    "                       ('rf', rf)])\n",
    "params = {\n",
    "   # 'ReduceDim__k' : range(5, 11),\n",
    "    'rf__n_estimators' : range(3, 20),\n",
    "    'rf__max_depth' : range(1, 5),\n",
    "    'rf__max_features' : ['sqrt', 'log2', None]\n",
    "}\n",
    "rfcv = RandomizedSearchCV(rfpipeline, n_iter= 1000, scoring = 'accuracy', \n",
    "                          param_distributions=params, verbose=1, cv = 10, n_jobs = numCores, random_state=randomSeed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'xgb__max_depth' : [3, 4, 5, 6],\n",
    "    'xgb__learning_rate' : [0.05, 0.1, 0.2],\n",
    "    'xgb__n_estimators' : range(5, 21),\n",
    "    'xgb__subsample' : [0.8, 0.9, 0.95],\n",
    "    #'xgb__colsample_bytree' : [0.8, 0.9, 0.95],\n",
    "    'xgb__reg_alpha' : [0.05, 0.1, 0.2, 0.4],\n",
    "    'xgb__reg_lambda' : [0.05, 0.1, 0.2, 0.4],\n",
    "    'xgb__gamma' : [0.0001, 0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "xgb = xgboost.XGBClassifier(seed=randomSeed)\n",
    "xgbpipeline = Pipeline([#('preProcessing', preProc),\n",
    "                        ('xgb', xgb)])\n",
    "xgbcv = RandomizedSearchCV(xgbpipeline, n_iter = 500, cv=10, param_distributions =param_grid,\n",
    "                        scoring='accuracy', verbose = 1, n_jobs = numCores, random_state=randomSeed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MLENS] backend: threading\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BlendEnsemble(array_check=None, backend=None,\n",
       "       layers=[Layer(backend='threading', dtype=<class 'numpy.float32'>, n_jobs=-1,\n",
       "   name='layer-1', propagate_features=None, raise_on_exception=True,\n",
       "   random_state=None, shuffle=False,\n",
       "   stack=[Group(backend='threading', dtype=<class 'numpy.float32'>,\n",
       "   indexer=BlendIndex(X=None, raise_on_exception=...rer=None)],\n",
       "   n_jobs=-1, name='group-1', raise_on_exception=True, transformers=[])],\n",
       "   verbose=0)],\n",
       "       model_selection=False, n_jobs=None, raise_on_exception=True,\n",
       "       random_state=None, sample_size=20, scorer=None, shuffle=False,\n",
       "       test_size=0.5, verbose=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlens.ensemble import BlendEnsemble\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "estimators = [rfcv, xgbcv]\n",
    "ensemble = BlendEnsemble()\n",
    "ensemble.add(estimators, proba=True)   # Specify 'proba' here\n",
    "ensemble.add_meta(LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 204 candidates, totalling 2040 fits\n",
      "Fitting 10 folds for each of 204 candidates, totalling 2040 fits\n",
      "Fitting 10 folds for each of 500 candidates, totalling 5000 fits\n",
      "Fitting 10 folds for each of 500 candidates, totalling 5000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done 2040 out of 2040 | elapsed:  2.7min finished\n",
      "[Parallel(n_jobs=10)]: Done 2040 out of 2040 | elapsed:  3.4min finished\n",
      "[Parallel(n_jobs=10)]: Done 5000 out of 5000 | elapsed:  3.9min finished\n",
      "[Parallel(n_jobs=10)]: Done 5000 out of 5000 | elapsed:  3.9min finished\n",
      "[Parallel(n_jobs=10)]: Done 2040 out of 2040 | elapsed:  3.9min finished\n",
      "[Parallel(n_jobs=10)]: Done 5000 out of 5000 | elapsed:  4.1min finished\n",
      "Exception ignored in: <bound method DMatrix.__del__ of <xgboost.core.DMatrix object at 0x000002A32C5610B8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\xgboost\\core.py\", line 482, in __del__\n",
      "    if self.handle is not None:\n",
      "AttributeError: 'DMatrix' object has no attribute 'handle'\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...wGPU\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\runpy.py in _run_code(code=<code object <module> at 0x000002A3233646F0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\...ges\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...wGPU\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\ProgramD...PU\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...wGPU\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x000002A3233646F0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\...ges\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...wGPU\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\ProgramD...PU\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    500         if self.poller is not None:\n    501             self.poller.start()\n    502         self.kernel.start()\n    503         self.io_loop = ioloop.IOLoop.current()\n    504         try:\n--> 505             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    506         except KeyboardInterrupt:\n    507             pass\n    508 \n    509 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\tornado\\platform\\asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    143         except (RuntimeError, AssertionError):\n    144             old_loop = None  # type: ignore\n    145         try:\n    146             self._setup_logging()\n    147             asyncio.set_event_loop(self.asyncio_loop)\n--> 148             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Win...EventLoop running=True closed=False debug=False>>\n    149         finally:\n    150             asyncio.set_event_loop(old_loop)\n    151 \n    152     def stop(self) -> None:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\asyncio\\base_events.py in run_forever(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n    422             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    423                                    finalizer=self._asyncgen_finalizer_hook)\n    424         try:\n    425             events._set_running_loop(self)\n    426             while True:\n--> 427                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_Windo...EventLoop running=True closed=False debug=False>>\n    428                 if self._stopping:\n    429                     break\n    430         finally:\n    431             self._stopping = False\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\asyncio\\base_events.py in _run_once(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n   1435                         logger.warning('Executing %s took %.3f seconds',\n   1436                                        _format_handle(handle), dt)\n   1437                 finally:\n   1438                     self._current_handle = None\n   1439             else:\n-> 1440                 handle._run()\n        handle._run = <bound method Handle._run of <Handle IOLoop.add_...flowGPU\\lib\\site-packages\\tornado\\ioloop.py:690>>\n   1441         handle = None  # Needed to break cycles when an exception occurs.\n   1442 \n   1443     def _set_coroutine_wrapper(self, enabled):\n   1444         try:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\asyncio\\events.py in _run(self=<Handle IOLoop.add_future.<locals>.<lambda>(<Fut...rflowGPU\\lib\\site-packages\\tornado\\ioloop.py:690>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <function IOLoop.add_future.<locals>.<lambda>>\n        self._args = (<Future finished result=(10, 32, <bound method.....61D31B8>, <zmq.sugar.fr...002A3261D3270>, ...]))>,)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\tornado\\ioloop.py in <lambda>(f=<Future finished result=(10, 32, <bound method.....61D31B8>, <zmq.sugar.fr...002A3261D3270>, ...]))>)\n    685             #\n    686             # Wrap the callback in self._run_callback so we control\n    687             # the error logging (i.e. it goes to tornado.log.app_log\n    688             # instead of asyncio's log).\n    689             future.add_done_callback(\n--> 690                 lambda f: self._run_callback(functools.partial(callback, future))\n        f = <Future finished result=(10, 32, <bound method.....61D31B8>, <zmq.sugar.fr...002A3261D3270>, ...]))>\n    691             )\n    692         else:\n    693             assert is_future(future)\n    694             # For concurrent futures, we use self.add_callback, so\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\tornado\\ioloop.py in _run_callback(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, callback=functools.partial(<function Runner.handle_yield....1D31B8>, <zmq.sugar.fr...002A3261D3270>, ...]))>))\n    738         .. versionchanged:: 6.0\n    739 \n    740            CancelledErrors are no longer logged.\n    741         \"\"\"\n    742         try:\n--> 743             ret = callback()\n        ret = undefined\n        callback = functools.partial(<function Runner.handle_yield....1D31B8>, <zmq.sugar.fr...002A3261D3270>, ...]))>)\n    744             if ret is not None:\n    745                 from tornado import gen\n    746 \n    747                 # Functions that return Futures typically swallow all\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\tornado\\gen.py in inner(f=None)\n    776         elif not self.future.done():\n    777 \n    778             def inner(f: Any) -> None:\n    779                 # Break a reference cycle to speed GC.\n    780                 f = None  # noqa: F841\n--> 781                 self.run()\n    782 \n    783             self.io_loop.add_future(self.future, inner)\n    784             return False\n    785         return True\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\tornado\\gen.py in run(self=<tornado.gen.Runner object>)\n    737                         finally:\n    738                             # Break up a reference to itself\n    739                             # for faster GC on CPython.\n    740                             exc_info = None\n    741                     else:\n--> 742                         yielded = self.gen.send(value)\n        yielded = undefined\n        self.gen.send = <built-in method send of generator object>\n        value = (10, 32, <bound method Kernel.dispatch_shell of <ipykernel.ipkernel.IPythonKernel object>>, (<zmq.eventloop.zmqstream.ZMQStream object>, [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]))\n    743 \n    744                 except (StopIteration, Return) as e:\n    745                     self.finished = True\n    746                     self.future = _null_future\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\ipykernel\\kernelbase.py in process_one(self=<ipykernel.ipkernel.IPythonKernel object>, wait=True)\n    352         else:\n    353             try:\n    354                 priority, t, dispatch, args = self.msg_queue.get_nowait()\n    355             except QueueEmpty:\n    356                 return None\n--> 357         yield gen.maybe_future(dispatch(*args))\n        dispatch = <bound method Kernel.dispatch_shell of <ipykernel.ipkernel.IPythonKernel object>>\n        args = (<zmq.eventloop.zmqstream.ZMQStream object>, [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    358 \n    359     @gen.coroutine\n    360     def dispatch_queue(self):\n    361         \"\"\"Coroutine to preserve order of message handling\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\tornado\\gen.py in wrapper(*args=(<ipykernel.ipkernel.IPythonKernel object>, <zmq.eventloop.zmqstream.ZMQStream object>, [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]), **kwargs={})\n    204                 # avoid the cost of creating a Runner when the coroutine\n    205                 # never actually yields, which in turn allows us to\n    206                 # use \"optional\" coroutines in critical path code without\n    207                 # performance penalty for the synchronous case.\n    208                 try:\n--> 209                     yielded = next(result)\n        yielded = undefined\n        result = <generator object dispatch_shell>\n    210                 except (StopIteration, Return) as e:\n    211                     future_set_result_unless_cancelled(\n    212                         future, _value_from_stopiteration(e)\n    213                     )\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'ensemble.fit(dataProc.X_train.reindex(columns=so...acy_score(dataProc.y_test, y_test_stacking_pred))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 6, 22, 3, 47, 11, 377019, tzinfo=tzutc()), 'msg_id': '701f8c05ac084fb79eae078ffde3f248', 'msg_type': 'execute_request', 'session': '19ee29c83ceb4c8c9957b181ff677507', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '701f8c05ac084fb79eae078ffde3f248', 'msg_type': 'execute_request', 'parent_header': {}})\n    262             try:\n    263                 self.pre_handler_hook()\n    264             except Exception:\n    265                 self.log.debug(\"Unable to signal in pre_handler_hook:\", exc_info=True)\n    266             try:\n--> 267                 yield gen.maybe_future(handler(stream, idents, msg))\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'19ee29c83ceb4c8c9957b181ff677507']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'ensemble.fit(dataProc.X_train.reindex(columns=so...acy_score(dataProc.y_test, y_test_stacking_pred))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 6, 22, 3, 47, 11, 377019, tzinfo=tzutc()), 'msg_id': '701f8c05ac084fb79eae078ffde3f248', 'msg_type': 'execute_request', 'session': '19ee29c83ceb4c8c9957b181ff677507', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '701f8c05ac084fb79eae078ffde3f248', 'msg_type': 'execute_request', 'parent_header': {}}\n    268             except Exception:\n    269                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    270             finally:\n    271                 try:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\tornado\\gen.py in wrapper(*args=(<ipykernel.ipkernel.IPythonKernel object>, <zmq.eventloop.zmqstream.ZMQStream object>, [b'19ee29c83ceb4c8c9957b181ff677507'], {'buffers': [], 'content': {'allow_stdin': True, 'code': 'ensemble.fit(dataProc.X_train.reindex(columns=so...acy_score(dataProc.y_test, y_test_stacking_pred))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 6, 22, 3, 47, 11, 377019, tzinfo=tzutc()), 'msg_id': '701f8c05ac084fb79eae078ffde3f248', 'msg_type': 'execute_request', 'session': '19ee29c83ceb4c8c9957b181ff677507', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '701f8c05ac084fb79eae078ffde3f248', 'msg_type': 'execute_request', 'parent_header': {}}), **kwargs={})\n    204                 # avoid the cost of creating a Runner when the coroutine\n    205                 # never actually yields, which in turn allows us to\n    206                 # use \"optional\" coroutines in critical path code without\n    207                 # performance penalty for the synchronous case.\n    208                 try:\n--> 209                     yielded = next(result)\n        yielded = undefined\n        result = <generator object execute_request>\n    210                 except (StopIteration, Return) as e:\n    211                     future_set_result_unless_cancelled(\n    212                         future, _value_from_stopiteration(e)\n    213                     )\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'19ee29c83ceb4c8c9957b181ff677507'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'ensemble.fit(dataProc.X_train.reindex(columns=so...acy_score(dataProc.y_test, y_test_stacking_pred))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 6, 22, 3, 47, 11, 377019, tzinfo=tzutc()), 'msg_id': '701f8c05ac084fb79eae078ffde3f248', 'msg_type': 'execute_request', 'session': '19ee29c83ceb4c8c9957b181ff677507', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '701f8c05ac084fb79eae078ffde3f248', 'msg_type': 'execute_request', 'parent_header': {}})\n    529             self._publish_execute_input(code, parent, self.execution_count)\n    530 \n    531         reply_content = yield gen.maybe_future(\n    532             self.do_execute(\n    533                 code, silent, store_history,\n--> 534                 user_expressions, allow_stdin,\n        user_expressions = {}\n        allow_stdin = True\n    535             )\n    536         )\n    537 \n    538         # Flush output before sending the reply.\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\tornado\\gen.py in wrapper(*args=(<ipykernel.ipkernel.IPythonKernel object>, 'ensemble.fit(dataProc.X_train.reindex(columns=so...acy_score(dataProc.y_test, y_test_stacking_pred))', False, True, {}, True), **kwargs={})\n    204                 # avoid the cost of creating a Runner when the coroutine\n    205                 # never actually yields, which in turn allows us to\n    206                 # use \"optional\" coroutines in critical path code without\n    207                 # performance penalty for the synchronous case.\n    208                 try:\n--> 209                     yielded = next(result)\n        yielded = undefined\n        result = <generator object do_execute>\n    210                 except (StopIteration, Return) as e:\n    211                     future_set_result_unless_cancelled(\n    212                         future, _value_from_stopiteration(e)\n    213                     )\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='ensemble.fit(dataProc.X_train.reindex(columns=so...acy_score(dataProc.y_test, y_test_stacking_pred))', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    289                     res = yield coro_future\n    290             else:\n    291                 # runner isn't already running,\n    292                 # make synchronous call,\n    293                 # letting shell dispatch to loop runners\n--> 294                 res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        code = 'ensemble.fit(dataProc.X_train.reindex(columns=so...acy_score(dataProc.y_test, y_test_stacking_pred))'\n        store_history = True\n        silent = False\n    295         finally:\n    296             self._restore_input()\n    297 \n    298         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('ensemble.fit(dataProc.X_train.reindex(columns=so...acy_score(dataProc.y_test, y_test_stacking_pred))',), **kwargs={'silent': False, 'store_history': True})\n    531             )\n    532         self.payload_manager.write_payload(payload)\n    533 \n    534     def run_cell(self, *args, **kwargs):\n    535         self._last_traceback = None\n--> 536         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('ensemble.fit(dataProc.X_train.reindex(columns=so...acy_score(dataProc.y_test, y_test_stacking_pred))',)\n        kwargs = {'silent': False, 'store_history': True}\n    537 \n    538     def _showtraceback(self, etype, evalue, stb):\n    539         # try to preserve ordering of tracebacks and print statements\n    540         sys.stdout.flush()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='ensemble.fit(dataProc.X_train.reindex(columns=so...acy_score(dataProc.y_test, y_test_stacking_pred))', store_history=True, silent=False, shell_futures=True)\n   2843         result : :class:`ExecutionResult`\n   2844         \"\"\"\n   2845         result = None\n   2846         try:\n   2847             result = self._run_cell(\n-> 2848                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = 'ensemble.fit(dataProc.X_train.reindex(columns=so...acy_score(dataProc.y_test, y_test_stacking_pred))'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2849         finally:\n   2850             self.events.trigger('post_execute')\n   2851             if not silent:\n   2852                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='ensemble.fit(dataProc.X_train.reindex(columns=so...acy_score(dataProc.y_test, y_test_stacking_pred))', store_history=True, silent=False, shell_futures=True)\n   2869             runner = self.loop_runner\n   2870         else:\n   2871             runner = _pseudo_sync_runner\n   2872 \n   2873         try:\n-> 2874             return runner(coro)\n        runner = <function _pseudo_sync_runner>\n        coro = <generator object InteractiveShell.run_cell_async>\n   2875         except BaseException as e:\n   2876             info = ExecutionInfo(raw_cell, store_history, silent, shell_futures)\n   2877             result = ExecutionResult(info)\n   2878             result.error_in_exec = e\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\IPython\\core\\async_helpers.py in _pseudo_sync_runner(coro=<generator object InteractiveShell.run_cell_async>)\n     62 \n     63     Credit to Nathaniel Smith\n     64 \n     65     \"\"\"\n     66     try:\n---> 67         coro.send(None)\n        coro.send = <built-in method send of generator object>\n     68     except StopIteration as exc:\n     69         return exc.value\n     70     else:\n     71         # TODO: do not raise but return an execution result with the right info.\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell_async(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='ensemble.fit(dataProc.X_train.reindex(columns=so...acy_score(dataProc.y_test, y_test_stacking_pred))', store_history=True, silent=False, shell_futures=True)\n   3044                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   3045                 if _run_async:\n   3046                     interactivity = 'async'\n   3047 \n   3048                 has_raised = yield from self.run_ast_nodes(code_ast.body, cell_name,\n-> 3049                        interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   3050 \n   3051                 self.last_execution_succeeded = not has_raised\n   3052                 self.last_execution_result = result\n   3053 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-30-9587da1d2955>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 2a32b141518, executio...rue silent=False shell_futures=True> result=None>)\n   3209                     return True\n   3210             else:\n   3211                 for i, node in enumerate(to_run_exec):\n   3212                     mod = Module([node], [])\n   3213                     code = compiler(mod, cell_name, \"exec\")\n-> 3214                     if (yield from self.run_code(code, result)):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000002A32B507D20, file \"<ipython-input-30-9587da1d2955>\", line 2>\n        result = <ExecutionResult object at 2a32b141518, executio...rue silent=False shell_futures=True> result=None>\n   3215                         return True\n   3216 \n   3217                 for i, node in enumerate(to_run_interactive):\n   3218                     mod = ast.Interactive([node])\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000002A32B507D20, file \"<ipython-input-30-9587da1d2955>\", line 2>, result=<ExecutionResult object at 2a32b141518, executio...rue silent=False shell_futures=True> result=None>, async_=False)\n   3291                 if async_:\n   3292                     last_expr = (yield from self._async_exec(code_obj, self.user_ns))\n   3293                     code = compile('last_expr', 'fake', \"single\")\n   3294                     exec(code, {'last_expr': last_expr})\n   3295                 else:\n-> 3296                     exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000002A32B507D20, file \"<ipython-input-30-9587da1d2955>\", line 2>\n        self.user_global_ns = {'BlendEnsemble': <class 'mlens.ensemble.blend.BlendEnsemble'>, 'ColumnTransformer': <class 'sklearn.compose._column_transformer.ColumnTransformer'>, 'DataProcessing': <class 'HelperClass.DataProcessing.DataProcessing'>, 'GenericUnivariateSelect': <class 'sklearn.feature_selection.univariate_selection.GenericUnivariateSelect'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'def warn(*args, **kwargs):\\n    pass\\nimport warnings\\nwarnings.warn = warn', \"import pandas as pd\\nimport numpy as np\\nimport im...inline')\\nfrom HelperClass.DataProcessing import *\", \"trainDataFile = 'Data/train.csv'\\ntestDataFile = ...randomSeed = 83213\\ntestRatio = 0.20\\nnumCores = 10\", 'dataProc = DataProcessing(trainDataFile, dataTyp...llData[~submitDataProc.AllData.Embarked.isnull()]', \"def PopulateFeatures(data):\\n    data.Cabin.filln...ata.Cabin.fillna('NA').str.get(0)\\n    return data\", 'dataProc.AllData = PopulateFeatures(dataProc.All...llData = PopulateFeatures(submitDataProc.AllData)', \"dataProc.AllData['CabinType_B_D_E'] = np.where(d...oc.AllData.CabinType.isin(['B', 'D', 'E']), 2, 1)\", 'dataProc.AllData.Age.fillna(-999, inplace=True)\\n...itDataProc.AllData.Age.fillna(-999, inplace=True)', 'bins = [-10000, 0, 20, 60, 1000]\\ndataProc.AllDat...cut(submitDataProc.AllData.Age, bins).astype(str)', \"dataProc.AllData['GenderAgeGroup'] = dataProc.Al...lData.Sex + '_' + submitDataProc.AllData.AgeGroup\", \"dataProc.AllData.groupby(['GenderAgeGroup']).agg...                                 ascending=False)\", \"genderAgeGroups = {\\n    'GenderAgeGroup' : {\\n   ..., 0]' : 2, \\n        'male_(60, 1000]' : 1\\n    }\\n}\", 'dataProc.AllData.replace(genderAgeGroups, inplac...oc.AllData.replace(genderAgeGroups, inplace=True)', \"dataProc.AllData['Sex'] = np.where(dataProc.AllD...re(submitDataProc.AllData['Sex'] == 'male', 1, 2)\", \"embarkedEncoding = {\\n    'Embarked' : {\\n       'S' : 1,\\n       'Q' : 1,\\n       'C' : 2\\n    }\\n}\", 'dataProc.AllData.replace(embarkedEncoding, inpla...c.AllData.replace(embarkedEncoding, inplace=True)', \"numCols = ['Fare', 'Pclass', 'Parch', 'CabinType_B_D_E', 'GenderAgeGroup', 'Embarked', 'Sex']\", 'dataProc.PopulateFeatureColumns(numCols)\\nsubmitDataProc.PopulateFeatureColumns(numCols)', 'dataProc.PopulateFeatureAndLabel(target)\\nsubmitDataProc.X = submitDataProc.AllData[numCols]', ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'OneHotEncoder': <class 'sklearn.preprocessing._encoders.OneHotEncoder'>, 'Out': {11:                     Survived      \n             ...0.129032   124\nmale_(60, 1000]     0.105263    19, 25:      CabinType_B_D_E  Embarked      Fare  Gender...    3      0       2    1\n\n[711 rows x 7 columns], 26: array(['CabinType_B_D_E', 'Embarked', 'Fare', 'G..., 'Parch',\n       'Pclass', 'Sex'], dtype=object), 27:      CabinType_B_D_E  Embarked      Fare  Gender...    2      1       3    1\n\n[418 rows x 7 columns], 28: BlendEnsemble(array_check=None, backend=None,\n  ...uffle=False,\n       test_size=0.5, verbose=False)}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, ...}\n        self.user_ns = {'BlendEnsemble': <class 'mlens.ensemble.blend.BlendEnsemble'>, 'ColumnTransformer': <class 'sklearn.compose._column_transformer.ColumnTransformer'>, 'DataProcessing': <class 'HelperClass.DataProcessing.DataProcessing'>, 'GenericUnivariateSelect': <class 'sklearn.feature_selection.univariate_selection.GenericUnivariateSelect'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'def warn(*args, **kwargs):\\n    pass\\nimport warnings\\nwarnings.warn = warn', \"import pandas as pd\\nimport numpy as np\\nimport im...inline')\\nfrom HelperClass.DataProcessing import *\", \"trainDataFile = 'Data/train.csv'\\ntestDataFile = ...randomSeed = 83213\\ntestRatio = 0.20\\nnumCores = 10\", 'dataProc = DataProcessing(trainDataFile, dataTyp...llData[~submitDataProc.AllData.Embarked.isnull()]', \"def PopulateFeatures(data):\\n    data.Cabin.filln...ata.Cabin.fillna('NA').str.get(0)\\n    return data\", 'dataProc.AllData = PopulateFeatures(dataProc.All...llData = PopulateFeatures(submitDataProc.AllData)', \"dataProc.AllData['CabinType_B_D_E'] = np.where(d...oc.AllData.CabinType.isin(['B', 'D', 'E']), 2, 1)\", 'dataProc.AllData.Age.fillna(-999, inplace=True)\\n...itDataProc.AllData.Age.fillna(-999, inplace=True)', 'bins = [-10000, 0, 20, 60, 1000]\\ndataProc.AllDat...cut(submitDataProc.AllData.Age, bins).astype(str)', \"dataProc.AllData['GenderAgeGroup'] = dataProc.Al...lData.Sex + '_' + submitDataProc.AllData.AgeGroup\", \"dataProc.AllData.groupby(['GenderAgeGroup']).agg...                                 ascending=False)\", \"genderAgeGroups = {\\n    'GenderAgeGroup' : {\\n   ..., 0]' : 2, \\n        'male_(60, 1000]' : 1\\n    }\\n}\", 'dataProc.AllData.replace(genderAgeGroups, inplac...oc.AllData.replace(genderAgeGroups, inplace=True)', \"dataProc.AllData['Sex'] = np.where(dataProc.AllD...re(submitDataProc.AllData['Sex'] == 'male', 1, 2)\", \"embarkedEncoding = {\\n    'Embarked' : {\\n       'S' : 1,\\n       'Q' : 1,\\n       'C' : 2\\n    }\\n}\", 'dataProc.AllData.replace(embarkedEncoding, inpla...c.AllData.replace(embarkedEncoding, inplace=True)', \"numCols = ['Fare', 'Pclass', 'Parch', 'CabinType_B_D_E', 'GenderAgeGroup', 'Embarked', 'Sex']\", 'dataProc.PopulateFeatureColumns(numCols)\\nsubmitDataProc.PopulateFeatureColumns(numCols)', 'dataProc.PopulateFeatureAndLabel(target)\\nsubmitDataProc.X = submitDataProc.AllData[numCols]', ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'OneHotEncoder': <class 'sklearn.preprocessing._encoders.OneHotEncoder'>, 'Out': {11:                     Survived      \n             ...0.129032   124\nmale_(60, 1000]     0.105263    19, 25:      CabinType_B_D_E  Embarked      Fare  Gender...    3      0       2    1\n\n[711 rows x 7 columns], 26: array(['CabinType_B_D_E', 'Embarked', 'Fare', 'G..., 'Parch',\n       'Pclass', 'Sex'], dtype=object), 27:      CabinType_B_D_E  Embarked      Fare  Gender...    2      1       3    1\n\n[418 rows x 7 columns], 28: BlendEnsemble(array_check=None, backend=None,\n  ...uffle=False,\n       test_size=0.5, verbose=False)}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, ...}\n   3297             finally:\n   3298                 # Reset our crash handler in place\n   3299                 sys.excepthook = old_excepthook\n   3300         except SystemExit as e:\n\n...........................................................................\nC:\\WIP\\Titanic\\<ipython-input-30-9587da1d2955> in <module>()\n      1 ensemble.fit(dataProc.X_train.reindex(columns=sortedCols), dataProc.y_train)\n----> 2 y_test_stacking_pred = ensemble.predict(dataProc.X_test)\n      3 print('Stacking Random Forest and XGB %.3f ' % accuracy_score(dataProc.y_test, y_test_stacking_pred))\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\ensemble\\base.py in predict(self=BlendEnsemble(array_check=None, backend=None,\n  ...uffle=False,\n       test_size=0.5, verbose=False), X=       Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns], **kwargs={})\n    605             predictions for provided input array.\n    606         \"\"\"\n    607         if not check_ensemble_build(self._backend):\n    608             # No layers instantiated, but raise_on_exception is False\n    609             return\n--> 610         return self._backend.predict(X, **kwargs)\n        self._backend.predict = <bound method Sequential.predict of Sequential(b...rmers=[])],\n   verbose=0)],\n      verbose=False)>\n        X =        Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns]\n        kwargs = {}\n    611 \n    612     def predict_proba(self, X, **kwargs):\n    613         \"\"\"Predict class probabilities with fitted ensemble.\n    614 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\ensemble\\base.py in predict(self=Sequential(backend='threading', dtype=<class 'nu...ormers=[])],\n   verbose=0)],\n      verbose=False), X=       Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns], **kwargs={})\n    201         if not self.__fitted__:\n    202             NotFittedError(\"Instance not fitted.\")\n    203 \n    204         f, t0 = print_job(self, \"Predicting\")\n    205 \n--> 206         out = self._predict(X, 'predict', **kwargs)\n        out = undefined\n        self._predict = <bound method Sequential._predict of Sequential(...rmers=[])],\n   verbose=0)],\n      verbose=False)>\n        X =        Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns]\n        kwargs = {}\n    207 \n    208         if self.verbose:\n    209             print_time(t0, \"{:<35}\".format(\"Predict complete\"),\n    210                        file=f, flush=True)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\ensemble\\base.py in _predict(self=Sequential(backend='threading', dtype=<class 'nu...ormers=[])],\n   verbose=0)],\n      verbose=False), X=       Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns], job='predict', **kwargs={})\n    261             data.\n    262         \"\"\"\n    263         r = kwargs.pop('return_preds', True)\n    264         with ParallelProcessing(self.backend, self.n_jobs,\n    265                                 max(self.verbose - 4, 0)) as manager:\n--> 266             out = manager.stack(self, job, X, return_preds=r, **kwargs)\n        out = undefined\n        manager.stack = <bound method ParallelProcessing.stack of <mlens.parallel.backend.ParallelProcessing object>>\n        self = Sequential(backend='threading', dtype=<class 'nu...ormers=[])],\n   verbose=0)],\n      verbose=False)\n        job = 'predict'\n        X =        Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns]\n        r = True\n        kwargs = {}\n    267 \n    268         if not isinstance(out, list):\n    269             out = [out]\n    270         out = [p.squeeze() for p in out]\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\parallel\\backend.py in stack(self=<mlens.parallel.backend.ParallelProcessing object>, caller=Sequential(backend='threading', dtype=<class 'nu...ormers=[])],\n   verbose=0)],\n      verbose=False), job='predict', X=       Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns], y=None, path=None, return_preds=True, warm_start=False, split=True, **kwargs={})\n    668             Prediction array(s).\n    669         \"\"\"\n    670         out = self.initialize(\n    671             job=job, X=X, y=y, path=path, warm_start=warm_start,\n    672             return_preds=return_preds, split=split, stack=True)\n--> 673         return self.process(caller=caller, out=out, **kwargs)\n        self.process = <bound method ParallelProcessing.process of <mlens.parallel.backend.ParallelProcessing object>>\n        caller = Sequential(backend='threading', dtype=<class 'nu...ormers=[])],\n   verbose=0)],\n      verbose=False)\n        out = {}\n        kwargs = {}\n    674 \n    675     def process(self, caller, out, **kwargs):\n    676         \"\"\"Process job.\n    677 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\parallel\\backend.py in process(self=<mlens.parallel.backend.ParallelProcessing object>, caller=Sequential(backend='threading', dtype=<class 'nu...ormers=[])],\n   verbose=0)],\n      verbose=False), out=None, **kwargs={})\n    713                       backend=self.backend) as parallel:\n    714 \n    715             for task in caller:\n    716                 self.job.clear()\n    717 \n--> 718                 self._partial_process(task, parallel, **kwargs)\n        self._partial_process = <bound method ParallelProcessing._partial_proces...lens.parallel.backend.ParallelProcessing object>>\n        task = Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=0)\n        parallel = Parallel(n_jobs=-1)\n        kwargs = {}\n    719 \n    720                 if task.name in return_names:\n    721                     out.append(self.get_preds(dtype=_dtype(task)))\n    722 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\parallel\\backend.py in _partial_process(self=<mlens.parallel.backend.ParallelProcessing object>, task=Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=0), parallel=Parallel(n_jobs=-1), **kwargs={})\n    734         task.setup(self.job.predict_in, self.job.targets, self.job.job)\n    735 \n    736         if not task.__no_output__:\n    737             self._gen_prediction_array(task, self.job.job, self.__threading__)\n    738 \n--> 739         task(self.job.args(**kwargs), parallel=parallel)\n        task = Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=0)\n        self.job.args = <bound method Job.args of <mlens.parallel.backend.Job object>>\n        kwargs = {}\n        parallel = Parallel(n_jobs=-1)\n    740 \n    741         if not task.__no_output__ and getattr(task, 'n_feature_prop', 0):\n    742             self._propagate_features(task)\n    743 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\parallel\\layer.py in __call__(self=Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=0), args={'auxiliary': {'P': None, 'X':        Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns]}, 'dir': [], 'job': 'predict', 'main': {'P': array([[0., 0., 0., 0.],\n       [0., 0., 0., 0.]...0., 0.],\n       [0., 0., 0., 0.]], dtype=float32), 'X':        Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns]}}, parallel=Parallel(n_jobs=-1))\n    147         if self.verbose >= 2:\n    148             safe_print(msg.format('Learners ...'), file=f, end=e2)\n    149             t1 = time()\n    150 \n    151         parallel(delayed(sublearner, not _threading)()\n--> 152                  for learner in self.learners\n        self.learners = [Learner(attr='predict_proba', backend='threading...a=True,\n    raise_on_exception=True, scorer=None), Learner(attr='predict_proba', backend='threading...a=True,\n    raise_on_exception=True, scorer=None)]\n    153                  for sublearner in learner(args, 'main'))\n    154 \n    155         if self.verbose >= 2:\n    156             print_time(t1, 'done', file=f)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object Layer.__call__.<locals>.<genexpr>>)\n    788             if pre_dispatch == \"all\" or n_jobs == 1:\n    789                 # The iterable was consumed all at once by the above for loop.\n    790                 # No need to wait for async callbacks to trigger to\n    791                 # consumption.\n    792                 self._iterating = False\n--> 793             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    794             # Make sure that we get a last message telling us we are done\n    795             elapsed_time = time.time() - self._start_time\n    796             self._print('Done %3i out of %3i | elapsed: %s finished',\n    797                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Fri Jun 21 22:51:20 2019\nPID: 8636Python 3.6.7: C:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\python.exe\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\externals\\joblib\\parallel.py in __call__(self=<mlens.externals.joblib.parallel.BatchedCalls object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<mlens.parallel.learner.SubLearner object>, (), {})]\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <mlens.parallel.learner.SubLearner object>\n        args = ()\n        kwargs = {}\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\parallel\\learner.py in __call__(self=<mlens.parallel.learner.SubLearner object>)\n    119         else:\n    120             self.processing_index = ''\n    121 \n    122     def __call__(self):\n    123         \"\"\"Launch job\"\"\"\n--> 124         return getattr(self, self.job)()\n        self = <mlens.parallel.learner.SubLearner object>\n        self.job = 'predict'\n    125 \n    126     def fit(self, path=None):\n    127         \"\"\"Fit sub-learner\"\"\"\n    128         if path is None:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\parallel\\learner.py in predict(self=<mlens.parallel.learner.SubLearner object>, path=[])\n    154         if path is None:\n    155             path = self.path\n    156         t0 = time()\n    157         transformers = self._load_preprocess(path)\n    158 \n--> 159         self._predict(transformers, False)\n        self._predict = <bound method SubLearner._predict of <mlens.parallel.learner.SubLearner object>>\n        transformers = None\n    160         if self.verbose:\n    161             msg = \"{:<30} {}\".format(self.name_index, \"done\")\n    162             f = \"stdout\" if self.verbose < 10 - 3 else \"stderr\"\n    163             print_time(t0, msg, file=f)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\parallel\\learner.py in _predict(self=<mlens.parallel.learner.SubLearner object>, transformers=None, score_preds=False)\n    194         xtemp, ytemp = slice_array(self.in_array, self.targets, self.out_index)\n    195         t0 = time()\n    196 \n    197         if transformers:\n    198             xtemp, ytemp = transformers.transform(xtemp, ytemp)\n--> 199         predictions = getattr(self.estimator, self.attr)(xtemp)\n        predictions = undefined\n        self.estimator = RandomizedSearchCV(cv=10, error_score='raise-dep...rain_score='warn', scoring='accuracy', verbose=1)\n        self.attr = 'predict_proba'\n        xtemp =        Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns]\n    200 \n    201         self.pred_time_ = time() - t0\n    202 \n    203         # Assign predictions to matrix\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\sklearn\\utils\\metaestimators.py in <lambda>(*args=(       Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns],), **kwargs={})\n    113                     break\n    114             else:\n    115                 attrgetter(self.delegate_names[-1])(obj)\n    116 \n    117         # lambda, but not partial, allows help() to work with update_wrapper\n--> 118         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)\n        args = (       Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns],)\n        kwargs = {}\n    119         # update the docstring of the returned function\n    120         update_wrapper(out, self.fn)\n    121         return out\n    122 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\sklearn\\model_selection\\_search.py in predict_proba(self=RandomizedSearchCV(cv=10, error_score='raise-dep...rain_score='warn', scoring='accuracy', verbose=1), X=       Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns])\n    503             Must fulfill the input assumptions of the\n    504             underlying estimator.\n    505 \n    506         \"\"\"\n    507         self._check_is_fitted('predict_proba')\n--> 508         return self.best_estimator_.predict_proba(X)\n        self.best_estimator_.predict_proba = <function Pipeline.predict_proba>\n        X =        Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns]\n    509 \n    510     @if_delegate_has_method(delegate=('best_estimator_', 'estimator'))\n    511     def predict_log_proba(self, X):\n    512         \"\"\"Call predict_log_proba on the estimator with the best found parameters.\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\sklearn\\utils\\metaestimators.py in <lambda>(*args=(       Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns],), **kwargs={})\n    113                     break\n    114             else:\n    115                 attrgetter(self.delegate_names[-1])(obj)\n    116 \n    117         # lambda, but not partial, allows help() to work with update_wrapper\n--> 118         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)\n        args = (       Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns],)\n        kwargs = {}\n    119         # update the docstring of the returned function\n    120         update_wrapper(out, self.fn)\n    121         return out\n    122 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\sklearn\\pipeline.py in predict_proba(self=Pipeline(memory=None,\n     steps=[('rf', RandomF...3213, verbose=0,\n            warm_start=False))]), X=       Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns])\n    377         \"\"\"\n    378         Xt = X\n    379         for name, transform in self.steps[:-1]:\n    380             if transform is not None:\n    381                 Xt = transform.transform(Xt)\n--> 382         return self.steps[-1][-1].predict_proba(Xt)\n        self.steps.predict_proba = undefined\n        Xt =        Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns]\n    383 \n    384     @if_delegate_has_method(delegate='_final_estimator')\n    385     def decision_function(self, X):\n    386         \"\"\"Apply transforms, and decision_function of the final estimator\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\sklearn\\ensemble\\forest.py in predict_proba(self=RandomForestClassifier(bootstrap=True, class_wei...e=83213, verbose=0,\n            warm_start=False), X=       Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns])\n    578             The class probabilities of the input samples. The order of the\n    579             classes corresponds to that in the attribute `classes_`.\n    580         \"\"\"\n    581         check_is_fitted(self, 'estimators_')\n    582         # Check data\n--> 583         X = self._validate_X_predict(X)\n        X =        Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns]\n        self._validate_X_predict = <bound method BaseForest._validate_X_predict of ...=83213, verbose=0,\n            warm_start=False)>\n    584 \n    585         # Assign chunk of trees to jobs\n    586         n_jobs, _, _ = _partition_estimators(self.n_estimators, self.n_jobs)\n    587 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\sklearn\\ensemble\\forest.py in _validate_X_predict(self=RandomForestClassifier(bootstrap=True, class_wei...e=83213, verbose=0,\n            warm_start=False), X=       Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns])\n    357         \"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\n    358         if self.estimators_ is None or len(self.estimators_) == 0:\n    359             raise NotFittedError(\"Estimator not fitted, \"\n    360                                  \"call `fit` before exploiting the model.\")\n    361 \n--> 362         return self.estimators_[0]._validate_X_predict(X, check_input=True)\n        self.estimators_._validate_X_predict = undefined\n        X =        Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns]\n    363 \n    364     @property\n    365     def feature_importances_(self):\n    366         \"\"\"Return the feature importances (the higher, the more important the\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\sklearn\\tree\\tree.py in _validate_X_predict(self=DecisionTreeClassifier(class_weight=None, criter...         random_state=516035225, splitter='best'), X=       Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns], check_input=True)\n    372         return self\n    373 \n    374     def _validate_X_predict(self, X, check_input):\n    375         \"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\n    376         if check_input:\n--> 377             X = check_array(X, dtype=DTYPE, accept_sparse=\"csr\")\n        X =        Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns]\n    378             if issparse(X) and (X.indices.dtype != np.intc or\n    379                                 X.indptr.dtype != np.intc):\n    380                 raise ValueError(\"No support for np.int64 index based \"\n    381                                  \"sparse matrices\")\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\sklearn\\utils\\validation.py in check_array(array=       Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns], accept_sparse='csr', accept_large_sparse=True, dtype=<class 'numpy.float32'>, order=None, copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)\n    522         # thereby passing the test made in the lines following the scope\n    523         # of warnings context manager.\n    524         with warnings.catch_warnings():\n    525             try:\n    526                 warnings.simplefilter('error', ComplexWarning)\n--> 527                 array = np.asarray(array, dtype=dtype, order=order)\n        array =        Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns]\n        dtype = <class 'numpy.float32'>\n        order = None\n    528             except ComplexWarning:\n    529                 raise ValueError(\"Complex data not supported\\n\"\n    530                                  \"{}\\n\".format(array))\n    531 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\numpy\\core\\numeric.py in asarray(a=       Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns], dtype=<class 'numpy.float32'>, order=None)\n    533     False\n    534     >>> np.asanyarray(a) is a\n    535     True\n    536 \n    537     \"\"\"\n--> 538     return array(a, dtype, copy=False, order=order)\n        a =        Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns]\n        dtype = <class 'numpy.float32'>\n        order = None\n    539 \n    540 \n    541 @set_module('numpy')\n    542 def asanyarray(a, dtype=None, order=None):\n\nValueError: could not convert string to float: '(20, 60]'\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    349\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\parallel\\learner.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;34m\"\"\"Launch job\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\parallel\\learner.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\parallel\\learner.py\u001b[0m in \u001b[0;36m_predict\u001b[1;34m(self, transformers, score_preds)\u001b[0m\n\u001b[0;32m    198\u001b[0m             \u001b[0mxtemp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtemp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    507\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'predict_proba'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    381\u001b[0m                 \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    582\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    378\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    526\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 527\u001b[1;33m                 \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    528\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '(20, 60]'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    702\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    704\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    669\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 670\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    671\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mworker\u001b[1;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    358\u001b[0m             \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformat_exc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me_tb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTransportableException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Fri Jun 21 22:51:20 2019\nPID: 8636Python 3.6.7: C:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\python.exe\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\externals\\joblib\\parallel.py in __call__(self=<mlens.externals.joblib.parallel.BatchedCalls object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<mlens.parallel.learner.SubLearner object>, (), {})]\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <mlens.parallel.learner.SubLearner object>\n        args = ()\n        kwargs = {}\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\parallel\\learner.py in __call__(self=<mlens.parallel.learner.SubLearner object>)\n    119         else:\n    120             self.processing_index = ''\n    121 \n    122     def __call__(self):\n    123         \"\"\"Launch job\"\"\"\n--> 124         return getattr(self, self.job)()\n        self = <mlens.parallel.learner.SubLearner object>\n        self.job = 'predict'\n    125 \n    126     def fit(self, path=None):\n    127         \"\"\"Fit sub-learner\"\"\"\n    128         if path is None:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\parallel\\learner.py in predict(self=<mlens.parallel.learner.SubLearner object>, path=[])\n    154         if path is None:\n    155             path = self.path\n    156         t0 = time()\n    157         transformers = self._load_preprocess(path)\n    158 \n--> 159         self._predict(transformers, False)\n        self._predict = <bound method SubLearner._predict of <mlens.parallel.learner.SubLearner object>>\n        transformers = None\n    160         if self.verbose:\n    161             msg = \"{:<30} {}\".format(self.name_index, \"done\")\n    162             f = \"stdout\" if self.verbose < 10 - 3 else \"stderr\"\n    163             print_time(t0, msg, file=f)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\parallel\\learner.py in _predict(self=<mlens.parallel.learner.SubLearner object>, transformers=None, score_preds=False)\n    194         xtemp, ytemp = slice_array(self.in_array, self.targets, self.out_index)\n    195         t0 = time()\n    196 \n    197         if transformers:\n    198             xtemp, ytemp = transformers.transform(xtemp, ytemp)\n--> 199         predictions = getattr(self.estimator, self.attr)(xtemp)\n        predictions = undefined\n        self.estimator = RandomizedSearchCV(cv=10, error_score='raise-dep...rain_score='warn', scoring='accuracy', verbose=1)\n        self.attr = 'predict_proba'\n        xtemp =        Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns]\n    200 \n    201         self.pred_time_ = time() - t0\n    202 \n    203         # Assign predictions to matrix\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\sklearn\\utils\\metaestimators.py in <lambda>(*args=(       Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns],), **kwargs={})\n    113                     break\n    114             else:\n    115                 attrgetter(self.delegate_names[-1])(obj)\n    116 \n    117         # lambda, but not partial, allows help() to work with update_wrapper\n--> 118         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)\n        args = (       Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns],)\n        kwargs = {}\n    119         # update the docstring of the returned function\n    120         update_wrapper(out, self.fn)\n    121         return out\n    122 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\sklearn\\model_selection\\_search.py in predict_proba(self=RandomizedSearchCV(cv=10, error_score='raise-dep...rain_score='warn', scoring='accuracy', verbose=1), X=       Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns])\n    503             Must fulfill the input assumptions of the\n    504             underlying estimator.\n    505 \n    506         \"\"\"\n    507         self._check_is_fitted('predict_proba')\n--> 508         return self.best_estimator_.predict_proba(X)\n        self.best_estimator_.predict_proba = <function Pipeline.predict_proba>\n        X =        Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns]\n    509 \n    510     @if_delegate_has_method(delegate=('best_estimator_', 'estimator'))\n    511     def predict_log_proba(self, X):\n    512         \"\"\"Call predict_log_proba on the estimator with the best found parameters.\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\sklearn\\utils\\metaestimators.py in <lambda>(*args=(       Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns],), **kwargs={})\n    113                     break\n    114             else:\n    115                 attrgetter(self.delegate_names[-1])(obj)\n    116 \n    117         # lambda, but not partial, allows help() to work with update_wrapper\n--> 118         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)\n        args = (       Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns],)\n        kwargs = {}\n    119         # update the docstring of the returned function\n    120         update_wrapper(out, self.fn)\n    121         return out\n    122 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\sklearn\\pipeline.py in predict_proba(self=Pipeline(memory=None,\n     steps=[('rf', RandomF...3213, verbose=0,\n            warm_start=False))]), X=       Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns])\n    377         \"\"\"\n    378         Xt = X\n    379         for name, transform in self.steps[:-1]:\n    380             if transform is not None:\n    381                 Xt = transform.transform(Xt)\n--> 382         return self.steps[-1][-1].predict_proba(Xt)\n        self.steps.predict_proba = undefined\n        Xt =        Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns]\n    383 \n    384     @if_delegate_has_method(delegate='_final_estimator')\n    385     def decision_function(self, X):\n    386         \"\"\"Apply transforms, and decision_function of the final estimator\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\sklearn\\ensemble\\forest.py in predict_proba(self=RandomForestClassifier(bootstrap=True, class_wei...e=83213, verbose=0,\n            warm_start=False), X=       Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns])\n    578             The class probabilities of the input samples. The order of the\n    579             classes corresponds to that in the attribute `classes_`.\n    580         \"\"\"\n    581         check_is_fitted(self, 'estimators_')\n    582         # Check data\n--> 583         X = self._validate_X_predict(X)\n        X =        Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns]\n        self._validate_X_predict = <bound method BaseForest._validate_X_predict of ...=83213, verbose=0,\n            warm_start=False)>\n    584 \n    585         # Assign chunk of trees to jobs\n    586         n_jobs, _, _ = _partition_estimators(self.n_estimators, self.n_jobs)\n    587 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\sklearn\\ensemble\\forest.py in _validate_X_predict(self=RandomForestClassifier(bootstrap=True, class_wei...e=83213, verbose=0,\n            warm_start=False), X=       Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns])\n    357         \"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\n    358         if self.estimators_ is None or len(self.estimators_) == 0:\n    359             raise NotFittedError(\"Estimator not fitted, \"\n    360                                  \"call `fit` before exploiting the model.\")\n    361 \n--> 362         return self.estimators_[0]._validate_X_predict(X, check_input=True)\n        self.estimators_._validate_X_predict = undefined\n        X =        Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns]\n    363 \n    364     @property\n    365     def feature_importances_(self):\n    366         \"\"\"Return the feature importances (the higher, the more important the\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\sklearn\\tree\\tree.py in _validate_X_predict(self=DecisionTreeClassifier(class_weight=None, criter...         random_state=516035225, splitter='best'), X=       Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns], check_input=True)\n    372         return self\n    373 \n    374     def _validate_X_predict(self, X, check_input):\n    375         \"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\n    376         if check_input:\n--> 377             X = check_array(X, dtype=DTYPE, accept_sparse=\"csr\")\n        X =        Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns]\n    378             if issparse(X) and (X.indices.dtype != np.intc or\n    379                                 X.indptr.dtype != np.intc):\n    380                 raise ValueError(\"No support for np.int64 index based \"\n    381                                  \"sparse matrices\")\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\sklearn\\utils\\validation.py in check_array(array=       Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns], accept_sparse='csr', accept_large_sparse=True, dtype=<class 'numpy.float32'>, order=None, copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)\n    522         # thereby passing the test made in the lines following the scope\n    523         # of warnings context manager.\n    524         with warnings.catch_warnings():\n    525             try:\n    526                 warnings.simplefilter('error', ComplexWarning)\n--> 527                 array = np.asarray(array, dtype=dtype, order=order)\n        array =        Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns]\n        dtype = <class 'numpy.float32'>\n        order = None\n    528             except ComplexWarning:\n    529                 raise ValueError(\"Complex data not supported\\n\"\n    530                                  \"{}\\n\".format(array))\n    531 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\numpy\\core\\numeric.py in asarray(a=       Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns], dtype=<class 'numpy.float32'>, order=None)\n    533     False\n    534     >>> np.asanyarray(a) is a\n    535     True\n    536 \n    537     \"\"\"\n--> 538     return array(a, dtype, copy=False, order=order)\n        a =        Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns]\n        dtype = <class 'numpy.float32'>\n        order = None\n    539 \n    540 \n    541 @set_module('numpy')\n    542 def asanyarray(a, dtype=None, order=None):\n\nValueError: could not convert string to float: '(20, 60]'\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-9587da1d2955>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mensemble\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataProc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msortedCols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataProc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_test_stacking_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensemble\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataProc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Stacking Random Forest and XGB %.3f '\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataProc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_stacking_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\ensemble\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, **kwargs)\u001b[0m\n\u001b[0;32m    608\u001b[0m             \u001b[1;31m# No layers instantiated, but raise_on_exception is False\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\ensemble\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprint_job\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Predicting\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'predict'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\ensemble\\base.py\u001b[0m in \u001b[0;36m_predict\u001b[1;34m(self, X, job, **kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m         with ParallelProcessing(self.backend, self.n_jobs,\n\u001b[0;32m    265\u001b[0m                                 max(self.verbose - 4, 0)) as manager:\n\u001b[1;32m--> 266\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmanager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_preds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\parallel\\backend.py\u001b[0m in \u001b[0;36mstack\u001b[1;34m(self, caller, job, X, y, path, return_preds, warm_start, split, **kwargs)\u001b[0m\n\u001b[0;32m    671\u001b[0m             \u001b[0mjob\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarm_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarm_start\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m             return_preds=return_preds, split=split, stack=True)\n\u001b[1;32m--> 673\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcaller\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaller\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaller\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\parallel\\backend.py\u001b[0m in \u001b[0;36mprocess\u001b[1;34m(self, caller, out, **kwargs)\u001b[0m\n\u001b[0;32m    716\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 718\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_partial_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    719\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    720\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreturn_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\parallel\\backend.py\u001b[0m in \u001b[0;36m_partial_process\u001b[1;34m(self, task, parallel, **kwargs)\u001b[0m\n\u001b[0;32m    737\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gen_prediction_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__threading__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 739\u001b[1;33m         \u001b[0mtask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparallel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    740\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    741\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__no_output__\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'n_feature_prop'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\parallel\\layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, args, parallel)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         parallel(delayed(sublearner, not _threading)()\n\u001b[1;32m--> 152\u001b[1;33m                  \u001b[1;32mfor\u001b[0m \u001b[0mlearner\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearners\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m                  for sublearner in learner(args, 'main'))\n\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    791\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 793\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    794\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    795\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    742\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 744\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    745\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...wGPU\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\runpy.py in _run_code(code=<code object <module> at 0x000002A3233646F0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\...ges\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...wGPU\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\ProgramD...PU\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...wGPU\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x000002A3233646F0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\...ges\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...wGPU\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\ProgramD...PU\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    500         if self.poller is not None:\n    501             self.poller.start()\n    502         self.kernel.start()\n    503         self.io_loop = ioloop.IOLoop.current()\n    504         try:\n--> 505             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    506         except KeyboardInterrupt:\n    507             pass\n    508 \n    509 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\tornado\\platform\\asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    143         except (RuntimeError, AssertionError):\n    144             old_loop = None  # type: ignore\n    145         try:\n    146             self._setup_logging()\n    147             asyncio.set_event_loop(self.asyncio_loop)\n--> 148             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Win...EventLoop running=True closed=False debug=False>>\n    149         finally:\n    150             asyncio.set_event_loop(old_loop)\n    151 \n    152     def stop(self) -> None:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\asyncio\\base_events.py in run_forever(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n    422             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    423                                    finalizer=self._asyncgen_finalizer_hook)\n    424         try:\n    425             events._set_running_loop(self)\n    426             while True:\n--> 427                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_Windo...EventLoop running=True closed=False debug=False>>\n    428                 if self._stopping:\n    429                     break\n    430         finally:\n    431             self._stopping = False\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\asyncio\\base_events.py in _run_once(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n   1435                         logger.warning('Executing %s took %.3f seconds',\n   1436                                        _format_handle(handle), dt)\n   1437                 finally:\n   1438                     self._current_handle = None\n   1439             else:\n-> 1440                 handle._run()\n        handle._run = <bound method Handle._run of <Handle IOLoop.add_...flowGPU\\lib\\site-packages\\tornado\\ioloop.py:690>>\n   1441         handle = None  # Needed to break cycles when an exception occurs.\n   1442 \n   1443     def _set_coroutine_wrapper(self, enabled):\n   1444         try:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\asyncio\\events.py in _run(self=<Handle IOLoop.add_future.<locals>.<lambda>(<Fut...rflowGPU\\lib\\site-packages\\tornado\\ioloop.py:690>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <function IOLoop.add_future.<locals>.<lambda>>\n        self._args = (<Future finished result=(10, 32, <bound method.....61D31B8>, <zmq.sugar.fr...002A3261D3270>, ...]))>,)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\tornado\\ioloop.py in <lambda>(f=<Future finished result=(10, 32, <bound method.....61D31B8>, <zmq.sugar.fr...002A3261D3270>, ...]))>)\n    685             #\n    686             # Wrap the callback in self._run_callback so we control\n    687             # the error logging (i.e. it goes to tornado.log.app_log\n    688             # instead of asyncio's log).\n    689             future.add_done_callback(\n--> 690                 lambda f: self._run_callback(functools.partial(callback, future))\n        f = <Future finished result=(10, 32, <bound method.....61D31B8>, <zmq.sugar.fr...002A3261D3270>, ...]))>\n    691             )\n    692         else:\n    693             assert is_future(future)\n    694             # For concurrent futures, we use self.add_callback, so\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\tornado\\ioloop.py in _run_callback(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, callback=functools.partial(<function Runner.handle_yield....1D31B8>, <zmq.sugar.fr...002A3261D3270>, ...]))>))\n    738         .. versionchanged:: 6.0\n    739 \n    740            CancelledErrors are no longer logged.\n    741         \"\"\"\n    742         try:\n--> 743             ret = callback()\n        ret = undefined\n        callback = functools.partial(<function Runner.handle_yield....1D31B8>, <zmq.sugar.fr...002A3261D3270>, ...]))>)\n    744             if ret is not None:\n    745                 from tornado import gen\n    746 \n    747                 # Functions that return Futures typically swallow all\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\tornado\\gen.py in inner(f=None)\n    776         elif not self.future.done():\n    777 \n    778             def inner(f: Any) -> None:\n    779                 # Break a reference cycle to speed GC.\n    780                 f = None  # noqa: F841\n--> 781                 self.run()\n    782 \n    783             self.io_loop.add_future(self.future, inner)\n    784             return False\n    785         return True\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\tornado\\gen.py in run(self=<tornado.gen.Runner object>)\n    737                         finally:\n    738                             # Break up a reference to itself\n    739                             # for faster GC on CPython.\n    740                             exc_info = None\n    741                     else:\n--> 742                         yielded = self.gen.send(value)\n        yielded = undefined\n        self.gen.send = <built-in method send of generator object>\n        value = (10, 32, <bound method Kernel.dispatch_shell of <ipykernel.ipkernel.IPythonKernel object>>, (<zmq.eventloop.zmqstream.ZMQStream object>, [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]))\n    743 \n    744                 except (StopIteration, Return) as e:\n    745                     self.finished = True\n    746                     self.future = _null_future\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\ipykernel\\kernelbase.py in process_one(self=<ipykernel.ipkernel.IPythonKernel object>, wait=True)\n    352         else:\n    353             try:\n    354                 priority, t, dispatch, args = self.msg_queue.get_nowait()\n    355             except QueueEmpty:\n    356                 return None\n--> 357         yield gen.maybe_future(dispatch(*args))\n        dispatch = <bound method Kernel.dispatch_shell of <ipykernel.ipkernel.IPythonKernel object>>\n        args = (<zmq.eventloop.zmqstream.ZMQStream object>, [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    358 \n    359     @gen.coroutine\n    360     def dispatch_queue(self):\n    361         \"\"\"Coroutine to preserve order of message handling\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\tornado\\gen.py in wrapper(*args=(<ipykernel.ipkernel.IPythonKernel object>, <zmq.eventloop.zmqstream.ZMQStream object>, [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]), **kwargs={})\n    204                 # avoid the cost of creating a Runner when the coroutine\n    205                 # never actually yields, which in turn allows us to\n    206                 # use \"optional\" coroutines in critical path code without\n    207                 # performance penalty for the synchronous case.\n    208                 try:\n--> 209                     yielded = next(result)\n        yielded = undefined\n        result = <generator object dispatch_shell>\n    210                 except (StopIteration, Return) as e:\n    211                     future_set_result_unless_cancelled(\n    212                         future, _value_from_stopiteration(e)\n    213                     )\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'ensemble.fit(dataProc.X_train.reindex(columns=so...acy_score(dataProc.y_test, y_test_stacking_pred))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 6, 22, 3, 47, 11, 377019, tzinfo=tzutc()), 'msg_id': '701f8c05ac084fb79eae078ffde3f248', 'msg_type': 'execute_request', 'session': '19ee29c83ceb4c8c9957b181ff677507', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '701f8c05ac084fb79eae078ffde3f248', 'msg_type': 'execute_request', 'parent_header': {}})\n    262             try:\n    263                 self.pre_handler_hook()\n    264             except Exception:\n    265                 self.log.debug(\"Unable to signal in pre_handler_hook:\", exc_info=True)\n    266             try:\n--> 267                 yield gen.maybe_future(handler(stream, idents, msg))\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'19ee29c83ceb4c8c9957b181ff677507']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'ensemble.fit(dataProc.X_train.reindex(columns=so...acy_score(dataProc.y_test, y_test_stacking_pred))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 6, 22, 3, 47, 11, 377019, tzinfo=tzutc()), 'msg_id': '701f8c05ac084fb79eae078ffde3f248', 'msg_type': 'execute_request', 'session': '19ee29c83ceb4c8c9957b181ff677507', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '701f8c05ac084fb79eae078ffde3f248', 'msg_type': 'execute_request', 'parent_header': {}}\n    268             except Exception:\n    269                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    270             finally:\n    271                 try:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\tornado\\gen.py in wrapper(*args=(<ipykernel.ipkernel.IPythonKernel object>, <zmq.eventloop.zmqstream.ZMQStream object>, [b'19ee29c83ceb4c8c9957b181ff677507'], {'buffers': [], 'content': {'allow_stdin': True, 'code': 'ensemble.fit(dataProc.X_train.reindex(columns=so...acy_score(dataProc.y_test, y_test_stacking_pred))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 6, 22, 3, 47, 11, 377019, tzinfo=tzutc()), 'msg_id': '701f8c05ac084fb79eae078ffde3f248', 'msg_type': 'execute_request', 'session': '19ee29c83ceb4c8c9957b181ff677507', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '701f8c05ac084fb79eae078ffde3f248', 'msg_type': 'execute_request', 'parent_header': {}}), **kwargs={})\n    204                 # avoid the cost of creating a Runner when the coroutine\n    205                 # never actually yields, which in turn allows us to\n    206                 # use \"optional\" coroutines in critical path code without\n    207                 # performance penalty for the synchronous case.\n    208                 try:\n--> 209                     yielded = next(result)\n        yielded = undefined\n        result = <generator object execute_request>\n    210                 except (StopIteration, Return) as e:\n    211                     future_set_result_unless_cancelled(\n    212                         future, _value_from_stopiteration(e)\n    213                     )\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'19ee29c83ceb4c8c9957b181ff677507'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'ensemble.fit(dataProc.X_train.reindex(columns=so...acy_score(dataProc.y_test, y_test_stacking_pred))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 6, 22, 3, 47, 11, 377019, tzinfo=tzutc()), 'msg_id': '701f8c05ac084fb79eae078ffde3f248', 'msg_type': 'execute_request', 'session': '19ee29c83ceb4c8c9957b181ff677507', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '701f8c05ac084fb79eae078ffde3f248', 'msg_type': 'execute_request', 'parent_header': {}})\n    529             self._publish_execute_input(code, parent, self.execution_count)\n    530 \n    531         reply_content = yield gen.maybe_future(\n    532             self.do_execute(\n    533                 code, silent, store_history,\n--> 534                 user_expressions, allow_stdin,\n        user_expressions = {}\n        allow_stdin = True\n    535             )\n    536         )\n    537 \n    538         # Flush output before sending the reply.\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\tornado\\gen.py in wrapper(*args=(<ipykernel.ipkernel.IPythonKernel object>, 'ensemble.fit(dataProc.X_train.reindex(columns=so...acy_score(dataProc.y_test, y_test_stacking_pred))', False, True, {}, True), **kwargs={})\n    204                 # avoid the cost of creating a Runner when the coroutine\n    205                 # never actually yields, which in turn allows us to\n    206                 # use \"optional\" coroutines in critical path code without\n    207                 # performance penalty for the synchronous case.\n    208                 try:\n--> 209                     yielded = next(result)\n        yielded = undefined\n        result = <generator object do_execute>\n    210                 except (StopIteration, Return) as e:\n    211                     future_set_result_unless_cancelled(\n    212                         future, _value_from_stopiteration(e)\n    213                     )\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='ensemble.fit(dataProc.X_train.reindex(columns=so...acy_score(dataProc.y_test, y_test_stacking_pred))', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    289                     res = yield coro_future\n    290             else:\n    291                 # runner isn't already running,\n    292                 # make synchronous call,\n    293                 # letting shell dispatch to loop runners\n--> 294                 res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        code = 'ensemble.fit(dataProc.X_train.reindex(columns=so...acy_score(dataProc.y_test, y_test_stacking_pred))'\n        store_history = True\n        silent = False\n    295         finally:\n    296             self._restore_input()\n    297 \n    298         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('ensemble.fit(dataProc.X_train.reindex(columns=so...acy_score(dataProc.y_test, y_test_stacking_pred))',), **kwargs={'silent': False, 'store_history': True})\n    531             )\n    532         self.payload_manager.write_payload(payload)\n    533 \n    534     def run_cell(self, *args, **kwargs):\n    535         self._last_traceback = None\n--> 536         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('ensemble.fit(dataProc.X_train.reindex(columns=so...acy_score(dataProc.y_test, y_test_stacking_pred))',)\n        kwargs = {'silent': False, 'store_history': True}\n    537 \n    538     def _showtraceback(self, etype, evalue, stb):\n    539         # try to preserve ordering of tracebacks and print statements\n    540         sys.stdout.flush()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='ensemble.fit(dataProc.X_train.reindex(columns=so...acy_score(dataProc.y_test, y_test_stacking_pred))', store_history=True, silent=False, shell_futures=True)\n   2843         result : :class:`ExecutionResult`\n   2844         \"\"\"\n   2845         result = None\n   2846         try:\n   2847             result = self._run_cell(\n-> 2848                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = 'ensemble.fit(dataProc.X_train.reindex(columns=so...acy_score(dataProc.y_test, y_test_stacking_pred))'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2849         finally:\n   2850             self.events.trigger('post_execute')\n   2851             if not silent:\n   2852                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='ensemble.fit(dataProc.X_train.reindex(columns=so...acy_score(dataProc.y_test, y_test_stacking_pred))', store_history=True, silent=False, shell_futures=True)\n   2869             runner = self.loop_runner\n   2870         else:\n   2871             runner = _pseudo_sync_runner\n   2872 \n   2873         try:\n-> 2874             return runner(coro)\n        runner = <function _pseudo_sync_runner>\n        coro = <generator object InteractiveShell.run_cell_async>\n   2875         except BaseException as e:\n   2876             info = ExecutionInfo(raw_cell, store_history, silent, shell_futures)\n   2877             result = ExecutionResult(info)\n   2878             result.error_in_exec = e\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\IPython\\core\\async_helpers.py in _pseudo_sync_runner(coro=<generator object InteractiveShell.run_cell_async>)\n     62 \n     63     Credit to Nathaniel Smith\n     64 \n     65     \"\"\"\n     66     try:\n---> 67         coro.send(None)\n        coro.send = <built-in method send of generator object>\n     68     except StopIteration as exc:\n     69         return exc.value\n     70     else:\n     71         # TODO: do not raise but return an execution result with the right info.\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell_async(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='ensemble.fit(dataProc.X_train.reindex(columns=so...acy_score(dataProc.y_test, y_test_stacking_pred))', store_history=True, silent=False, shell_futures=True)\n   3044                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   3045                 if _run_async:\n   3046                     interactivity = 'async'\n   3047 \n   3048                 has_raised = yield from self.run_ast_nodes(code_ast.body, cell_name,\n-> 3049                        interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   3050 \n   3051                 self.last_execution_succeeded = not has_raised\n   3052                 self.last_execution_result = result\n   3053 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-30-9587da1d2955>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 2a32b141518, executio...rue silent=False shell_futures=True> result=None>)\n   3209                     return True\n   3210             else:\n   3211                 for i, node in enumerate(to_run_exec):\n   3212                     mod = Module([node], [])\n   3213                     code = compiler(mod, cell_name, \"exec\")\n-> 3214                     if (yield from self.run_code(code, result)):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000002A32B507D20, file \"<ipython-input-30-9587da1d2955>\", line 2>\n        result = <ExecutionResult object at 2a32b141518, executio...rue silent=False shell_futures=True> result=None>\n   3215                         return True\n   3216 \n   3217                 for i, node in enumerate(to_run_interactive):\n   3218                     mod = ast.Interactive([node])\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000002A32B507D20, file \"<ipython-input-30-9587da1d2955>\", line 2>, result=<ExecutionResult object at 2a32b141518, executio...rue silent=False shell_futures=True> result=None>, async_=False)\n   3291                 if async_:\n   3292                     last_expr = (yield from self._async_exec(code_obj, self.user_ns))\n   3293                     code = compile('last_expr', 'fake', \"single\")\n   3294                     exec(code, {'last_expr': last_expr})\n   3295                 else:\n-> 3296                     exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000002A32B507D20, file \"<ipython-input-30-9587da1d2955>\", line 2>\n        self.user_global_ns = {'BlendEnsemble': <class 'mlens.ensemble.blend.BlendEnsemble'>, 'ColumnTransformer': <class 'sklearn.compose._column_transformer.ColumnTransformer'>, 'DataProcessing': <class 'HelperClass.DataProcessing.DataProcessing'>, 'GenericUnivariateSelect': <class 'sklearn.feature_selection.univariate_selection.GenericUnivariateSelect'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'def warn(*args, **kwargs):\\n    pass\\nimport warnings\\nwarnings.warn = warn', \"import pandas as pd\\nimport numpy as np\\nimport im...inline')\\nfrom HelperClass.DataProcessing import *\", \"trainDataFile = 'Data/train.csv'\\ntestDataFile = ...randomSeed = 83213\\ntestRatio = 0.20\\nnumCores = 10\", 'dataProc = DataProcessing(trainDataFile, dataTyp...llData[~submitDataProc.AllData.Embarked.isnull()]', \"def PopulateFeatures(data):\\n    data.Cabin.filln...ata.Cabin.fillna('NA').str.get(0)\\n    return data\", 'dataProc.AllData = PopulateFeatures(dataProc.All...llData = PopulateFeatures(submitDataProc.AllData)', \"dataProc.AllData['CabinType_B_D_E'] = np.where(d...oc.AllData.CabinType.isin(['B', 'D', 'E']), 2, 1)\", 'dataProc.AllData.Age.fillna(-999, inplace=True)\\n...itDataProc.AllData.Age.fillna(-999, inplace=True)', 'bins = [-10000, 0, 20, 60, 1000]\\ndataProc.AllDat...cut(submitDataProc.AllData.Age, bins).astype(str)', \"dataProc.AllData['GenderAgeGroup'] = dataProc.Al...lData.Sex + '_' + submitDataProc.AllData.AgeGroup\", \"dataProc.AllData.groupby(['GenderAgeGroup']).agg...                                 ascending=False)\", \"genderAgeGroups = {\\n    'GenderAgeGroup' : {\\n   ..., 0]' : 2, \\n        'male_(60, 1000]' : 1\\n    }\\n}\", 'dataProc.AllData.replace(genderAgeGroups, inplac...oc.AllData.replace(genderAgeGroups, inplace=True)', \"dataProc.AllData['Sex'] = np.where(dataProc.AllD...re(submitDataProc.AllData['Sex'] == 'male', 1, 2)\", \"embarkedEncoding = {\\n    'Embarked' : {\\n       'S' : 1,\\n       'Q' : 1,\\n       'C' : 2\\n    }\\n}\", 'dataProc.AllData.replace(embarkedEncoding, inpla...c.AllData.replace(embarkedEncoding, inplace=True)', \"numCols = ['Fare', 'Pclass', 'Parch', 'CabinType_B_D_E', 'GenderAgeGroup', 'Embarked', 'Sex']\", 'dataProc.PopulateFeatureColumns(numCols)\\nsubmitDataProc.PopulateFeatureColumns(numCols)', 'dataProc.PopulateFeatureAndLabel(target)\\nsubmitDataProc.X = submitDataProc.AllData[numCols]', ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'OneHotEncoder': <class 'sklearn.preprocessing._encoders.OneHotEncoder'>, 'Out': {11:                     Survived      \n             ...0.129032   124\nmale_(60, 1000]     0.105263    19, 25:      CabinType_B_D_E  Embarked      Fare  Gender...    3      0       2    1\n\n[711 rows x 7 columns], 26: array(['CabinType_B_D_E', 'Embarked', 'Fare', 'G..., 'Parch',\n       'Pclass', 'Sex'], dtype=object), 27:      CabinType_B_D_E  Embarked      Fare  Gender...    2      1       3    1\n\n[418 rows x 7 columns], 28: BlendEnsemble(array_check=None, backend=None,\n  ...uffle=False,\n       test_size=0.5, verbose=False)}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, ...}\n        self.user_ns = {'BlendEnsemble': <class 'mlens.ensemble.blend.BlendEnsemble'>, 'ColumnTransformer': <class 'sklearn.compose._column_transformer.ColumnTransformer'>, 'DataProcessing': <class 'HelperClass.DataProcessing.DataProcessing'>, 'GenericUnivariateSelect': <class 'sklearn.feature_selection.univariate_selection.GenericUnivariateSelect'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'def warn(*args, **kwargs):\\n    pass\\nimport warnings\\nwarnings.warn = warn', \"import pandas as pd\\nimport numpy as np\\nimport im...inline')\\nfrom HelperClass.DataProcessing import *\", \"trainDataFile = 'Data/train.csv'\\ntestDataFile = ...randomSeed = 83213\\ntestRatio = 0.20\\nnumCores = 10\", 'dataProc = DataProcessing(trainDataFile, dataTyp...llData[~submitDataProc.AllData.Embarked.isnull()]', \"def PopulateFeatures(data):\\n    data.Cabin.filln...ata.Cabin.fillna('NA').str.get(0)\\n    return data\", 'dataProc.AllData = PopulateFeatures(dataProc.All...llData = PopulateFeatures(submitDataProc.AllData)', \"dataProc.AllData['CabinType_B_D_E'] = np.where(d...oc.AllData.CabinType.isin(['B', 'D', 'E']), 2, 1)\", 'dataProc.AllData.Age.fillna(-999, inplace=True)\\n...itDataProc.AllData.Age.fillna(-999, inplace=True)', 'bins = [-10000, 0, 20, 60, 1000]\\ndataProc.AllDat...cut(submitDataProc.AllData.Age, bins).astype(str)', \"dataProc.AllData['GenderAgeGroup'] = dataProc.Al...lData.Sex + '_' + submitDataProc.AllData.AgeGroup\", \"dataProc.AllData.groupby(['GenderAgeGroup']).agg...                                 ascending=False)\", \"genderAgeGroups = {\\n    'GenderAgeGroup' : {\\n   ..., 0]' : 2, \\n        'male_(60, 1000]' : 1\\n    }\\n}\", 'dataProc.AllData.replace(genderAgeGroups, inplac...oc.AllData.replace(genderAgeGroups, inplace=True)', \"dataProc.AllData['Sex'] = np.where(dataProc.AllD...re(submitDataProc.AllData['Sex'] == 'male', 1, 2)\", \"embarkedEncoding = {\\n    'Embarked' : {\\n       'S' : 1,\\n       'Q' : 1,\\n       'C' : 2\\n    }\\n}\", 'dataProc.AllData.replace(embarkedEncoding, inpla...c.AllData.replace(embarkedEncoding, inplace=True)', \"numCols = ['Fare', 'Pclass', 'Parch', 'CabinType_B_D_E', 'GenderAgeGroup', 'Embarked', 'Sex']\", 'dataProc.PopulateFeatureColumns(numCols)\\nsubmitDataProc.PopulateFeatureColumns(numCols)', 'dataProc.PopulateFeatureAndLabel(target)\\nsubmitDataProc.X = submitDataProc.AllData[numCols]', ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'OneHotEncoder': <class 'sklearn.preprocessing._encoders.OneHotEncoder'>, 'Out': {11:                     Survived      \n             ...0.129032   124\nmale_(60, 1000]     0.105263    19, 25:      CabinType_B_D_E  Embarked      Fare  Gender...    3      0       2    1\n\n[711 rows x 7 columns], 26: array(['CabinType_B_D_E', 'Embarked', 'Fare', 'G..., 'Parch',\n       'Pclass', 'Sex'], dtype=object), 27:      CabinType_B_D_E  Embarked      Fare  Gender...    2      1       3    1\n\n[418 rows x 7 columns], 28: BlendEnsemble(array_check=None, backend=None,\n  ...uffle=False,\n       test_size=0.5, verbose=False)}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, ...}\n   3297             finally:\n   3298                 # Reset our crash handler in place\n   3299                 sys.excepthook = old_excepthook\n   3300         except SystemExit as e:\n\n...........................................................................\nC:\\WIP\\Titanic\\<ipython-input-30-9587da1d2955> in <module>()\n      1 ensemble.fit(dataProc.X_train.reindex(columns=sortedCols), dataProc.y_train)\n----> 2 y_test_stacking_pred = ensemble.predict(dataProc.X_test)\n      3 print('Stacking Random Forest and XGB %.3f ' % accuracy_score(dataProc.y_test, y_test_stacking_pred))\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\ensemble\\base.py in predict(self=BlendEnsemble(array_check=None, backend=None,\n  ...uffle=False,\n       test_size=0.5, verbose=False), X=       Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns], **kwargs={})\n    605             predictions for provided input array.\n    606         \"\"\"\n    607         if not check_ensemble_build(self._backend):\n    608             # No layers instantiated, but raise_on_exception is False\n    609             return\n--> 610         return self._backend.predict(X, **kwargs)\n        self._backend.predict = <bound method Sequential.predict of Sequential(b...rmers=[])],\n   verbose=0)],\n      verbose=False)>\n        X =        Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns]\n        kwargs = {}\n    611 \n    612     def predict_proba(self, X, **kwargs):\n    613         \"\"\"Predict class probabilities with fitted ensemble.\n    614 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\ensemble\\base.py in predict(self=Sequential(backend='threading', dtype=<class 'nu...ormers=[])],\n   verbose=0)],\n      verbose=False), X=       Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns], **kwargs={})\n    201         if not self.__fitted__:\n    202             NotFittedError(\"Instance not fitted.\")\n    203 \n    204         f, t0 = print_job(self, \"Predicting\")\n    205 \n--> 206         out = self._predict(X, 'predict', **kwargs)\n        out = undefined\n        self._predict = <bound method Sequential._predict of Sequential(...rmers=[])],\n   verbose=0)],\n      verbose=False)>\n        X =        Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns]\n        kwargs = {}\n    207 \n    208         if self.verbose:\n    209             print_time(t0, \"{:<35}\".format(\"Predict complete\"),\n    210                        file=f, flush=True)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\ensemble\\base.py in _predict(self=Sequential(backend='threading', dtype=<class 'nu...ormers=[])],\n   verbose=0)],\n      verbose=False), X=       Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns], job='predict', **kwargs={})\n    261             data.\n    262         \"\"\"\n    263         r = kwargs.pop('return_preds', True)\n    264         with ParallelProcessing(self.backend, self.n_jobs,\n    265                                 max(self.verbose - 4, 0)) as manager:\n--> 266             out = manager.stack(self, job, X, return_preds=r, **kwargs)\n        out = undefined\n        manager.stack = <bound method ParallelProcessing.stack of <mlens.parallel.backend.ParallelProcessing object>>\n        self = Sequential(backend='threading', dtype=<class 'nu...ormers=[])],\n   verbose=0)],\n      verbose=False)\n        job = 'predict'\n        X =        Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns]\n        r = True\n        kwargs = {}\n    267 \n    268         if not isinstance(out, list):\n    269             out = [out]\n    270         out = [p.squeeze() for p in out]\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\parallel\\backend.py in stack(self=<mlens.parallel.backend.ParallelProcessing object>, caller=Sequential(backend='threading', dtype=<class 'nu...ormers=[])],\n   verbose=0)],\n      verbose=False), job='predict', X=       Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns], y=None, path=None, return_preds=True, warm_start=False, split=True, **kwargs={})\n    668             Prediction array(s).\n    669         \"\"\"\n    670         out = self.initialize(\n    671             job=job, X=X, y=y, path=path, warm_start=warm_start,\n    672             return_preds=return_preds, split=split, stack=True)\n--> 673         return self.process(caller=caller, out=out, **kwargs)\n        self.process = <bound method ParallelProcessing.process of <mlens.parallel.backend.ParallelProcessing object>>\n        caller = Sequential(backend='threading', dtype=<class 'nu...ormers=[])],\n   verbose=0)],\n      verbose=False)\n        out = {}\n        kwargs = {}\n    674 \n    675     def process(self, caller, out, **kwargs):\n    676         \"\"\"Process job.\n    677 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\parallel\\backend.py in process(self=<mlens.parallel.backend.ParallelProcessing object>, caller=Sequential(backend='threading', dtype=<class 'nu...ormers=[])],\n   verbose=0)],\n      verbose=False), out=None, **kwargs={})\n    713                       backend=self.backend) as parallel:\n    714 \n    715             for task in caller:\n    716                 self.job.clear()\n    717 \n--> 718                 self._partial_process(task, parallel, **kwargs)\n        self._partial_process = <bound method ParallelProcessing._partial_proces...lens.parallel.backend.ParallelProcessing object>>\n        task = Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=0)\n        parallel = Parallel(n_jobs=-1)\n        kwargs = {}\n    719 \n    720                 if task.name in return_names:\n    721                     out.append(self.get_preds(dtype=_dtype(task)))\n    722 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\parallel\\backend.py in _partial_process(self=<mlens.parallel.backend.ParallelProcessing object>, task=Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=0), parallel=Parallel(n_jobs=-1), **kwargs={})\n    734         task.setup(self.job.predict_in, self.job.targets, self.job.job)\n    735 \n    736         if not task.__no_output__:\n    737             self._gen_prediction_array(task, self.job.job, self.__threading__)\n    738 \n--> 739         task(self.job.args(**kwargs), parallel=parallel)\n        task = Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=0)\n        self.job.args = <bound method Job.args of <mlens.parallel.backend.Job object>>\n        kwargs = {}\n        parallel = Parallel(n_jobs=-1)\n    740 \n    741         if not task.__no_output__ and getattr(task, 'n_feature_prop', 0):\n    742             self._propagate_features(task)\n    743 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\parallel\\layer.py in __call__(self=Layer(backend='threading', dtype=<class 'numpy.f..._exception=True, transformers=[])],\n   verbose=0), args={'auxiliary': {'P': None, 'X':        Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns]}, 'dir': [], 'job': 'predict', 'main': {'P': array([[0., 0., 0., 0.],\n       [0., 0., 0., 0.]...0., 0.],\n       [0., 0., 0., 0.]], dtype=float32), 'X':        Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns]}}, parallel=Parallel(n_jobs=-1))\n    147         if self.verbose >= 2:\n    148             safe_print(msg.format('Learners ...'), file=f, end=e2)\n    149             t1 = time()\n    150 \n    151         parallel(delayed(sublearner, not _threading)()\n--> 152                  for learner in self.learners\n        self.learners = [Learner(attr='predict_proba', backend='threading...a=True,\n    raise_on_exception=True, scorer=None), Learner(attr='predict_proba', backend='threading...a=True,\n    raise_on_exception=True, scorer=None)]\n    153                  for sublearner in learner(args, 'main'))\n    154 \n    155         if self.verbose >= 2:\n    156             print_time(t1, 'done', file=f)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object Layer.__call__.<locals>.<genexpr>>)\n    788             if pre_dispatch == \"all\" or n_jobs == 1:\n    789                 # The iterable was consumed all at once by the above for loop.\n    790                 # No need to wait for async callbacks to trigger to\n    791                 # consumption.\n    792                 self._iterating = False\n--> 793             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    794             # Make sure that we get a last message telling us we are done\n    795             elapsed_time = time.time() - self._start_time\n    796             self._print('Done %3i out of %3i | elapsed: %s finished',\n    797                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Fri Jun 21 22:51:20 2019\nPID: 8636Python 3.6.7: C:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\python.exe\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\externals\\joblib\\parallel.py in __call__(self=<mlens.externals.joblib.parallel.BatchedCalls object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<mlens.parallel.learner.SubLearner object>, (), {})]\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    130     def __init__(self, iterator_slice):\n    131         self.items = list(iterator_slice)\n    132         self._size = len(self.items)\n    133 \n    134     def __call__(self):\n--> 135         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <mlens.parallel.learner.SubLearner object>\n        args = ()\n        kwargs = {}\n    136 \n    137     def __len__(self):\n    138         return self._size\n    139 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\parallel\\learner.py in __call__(self=<mlens.parallel.learner.SubLearner object>)\n    119         else:\n    120             self.processing_index = ''\n    121 \n    122     def __call__(self):\n    123         \"\"\"Launch job\"\"\"\n--> 124         return getattr(self, self.job)()\n        self = <mlens.parallel.learner.SubLearner object>\n        self.job = 'predict'\n    125 \n    126     def fit(self, path=None):\n    127         \"\"\"Fit sub-learner\"\"\"\n    128         if path is None:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\parallel\\learner.py in predict(self=<mlens.parallel.learner.SubLearner object>, path=[])\n    154         if path is None:\n    155             path = self.path\n    156         t0 = time()\n    157         transformers = self._load_preprocess(path)\n    158 \n--> 159         self._predict(transformers, False)\n        self._predict = <bound method SubLearner._predict of <mlens.parallel.learner.SubLearner object>>\n        transformers = None\n    160         if self.verbose:\n    161             msg = \"{:<30} {}\".format(self.name_index, \"done\")\n    162             f = \"stdout\" if self.verbose < 10 - 3 else \"stderr\"\n    163             print_time(t0, msg, file=f)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\mlens\\parallel\\learner.py in _predict(self=<mlens.parallel.learner.SubLearner object>, transformers=None, score_preds=False)\n    194         xtemp, ytemp = slice_array(self.in_array, self.targets, self.out_index)\n    195         t0 = time()\n    196 \n    197         if transformers:\n    198             xtemp, ytemp = transformers.transform(xtemp, ytemp)\n--> 199         predictions = getattr(self.estimator, self.attr)(xtemp)\n        predictions = undefined\n        self.estimator = RandomizedSearchCV(cv=10, error_score='raise-dep...rain_score='warn', scoring='accuracy', verbose=1)\n        self.attr = 'predict_proba'\n        xtemp =        Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns]\n    200 \n    201         self.pred_time_ = time() - t0\n    202 \n    203         # Assign predictions to matrix\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\sklearn\\utils\\metaestimators.py in <lambda>(*args=(       Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns],), **kwargs={})\n    113                     break\n    114             else:\n    115                 attrgetter(self.delegate_names[-1])(obj)\n    116 \n    117         # lambda, but not partial, allows help() to work with update_wrapper\n--> 118         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)\n        args = (       Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns],)\n        kwargs = {}\n    119         # update the docstring of the returned function\n    120         update_wrapper(out, self.fn)\n    121         return out\n    122 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\sklearn\\model_selection\\_search.py in predict_proba(self=RandomizedSearchCV(cv=10, error_score='raise-dep...rain_score='warn', scoring='accuracy', verbose=1), X=       Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns])\n    503             Must fulfill the input assumptions of the\n    504             underlying estimator.\n    505 \n    506         \"\"\"\n    507         self._check_is_fitted('predict_proba')\n--> 508         return self.best_estimator_.predict_proba(X)\n        self.best_estimator_.predict_proba = <function Pipeline.predict_proba>\n        X =        Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns]\n    509 \n    510     @if_delegate_has_method(delegate=('best_estimator_', 'estimator'))\n    511     def predict_log_proba(self, X):\n    512         \"\"\"Call predict_log_proba on the estimator with the best found parameters.\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\sklearn\\utils\\metaestimators.py in <lambda>(*args=(       Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns],), **kwargs={})\n    113                     break\n    114             else:\n    115                 attrgetter(self.delegate_names[-1])(obj)\n    116 \n    117         # lambda, but not partial, allows help() to work with update_wrapper\n--> 118         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)\n        args = (       Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns],)\n        kwargs = {}\n    119         # update the docstring of the returned function\n    120         update_wrapper(out, self.fn)\n    121         return out\n    122 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\sklearn\\pipeline.py in predict_proba(self=Pipeline(memory=None,\n     steps=[('rf', RandomF...3213, verbose=0,\n            warm_start=False))]), X=       Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns])\n    377         \"\"\"\n    378         Xt = X\n    379         for name, transform in self.steps[:-1]:\n    380             if transform is not None:\n    381                 Xt = transform.transform(Xt)\n--> 382         return self.steps[-1][-1].predict_proba(Xt)\n        self.steps.predict_proba = undefined\n        Xt =        Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns]\n    383 \n    384     @if_delegate_has_method(delegate='_final_estimator')\n    385     def decision_function(self, X):\n    386         \"\"\"Apply transforms, and decision_function of the final estimator\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\sklearn\\ensemble\\forest.py in predict_proba(self=RandomForestClassifier(bootstrap=True, class_wei...e=83213, verbose=0,\n            warm_start=False), X=       Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns])\n    578             The class probabilities of the input samples. The order of the\n    579             classes corresponds to that in the attribute `classes_`.\n    580         \"\"\"\n    581         check_is_fitted(self, 'estimators_')\n    582         # Check data\n--> 583         X = self._validate_X_predict(X)\n        X =        Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns]\n        self._validate_X_predict = <bound method BaseForest._validate_X_predict of ...=83213, verbose=0,\n            warm_start=False)>\n    584 \n    585         # Assign chunk of trees to jobs\n    586         n_jobs, _, _ = _partition_estimators(self.n_estimators, self.n_jobs)\n    587 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\sklearn\\ensemble\\forest.py in _validate_X_predict(self=RandomForestClassifier(bootstrap=True, class_wei...e=83213, verbose=0,\n            warm_start=False), X=       Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns])\n    357         \"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\n    358         if self.estimators_ is None or len(self.estimators_) == 0:\n    359             raise NotFittedError(\"Estimator not fitted, \"\n    360                                  \"call `fit` before exploiting the model.\")\n    361 \n--> 362         return self.estimators_[0]._validate_X_predict(X, check_input=True)\n        self.estimators_._validate_X_predict = undefined\n        X =        Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns]\n    363 \n    364     @property\n    365     def feature_importances_(self):\n    366         \"\"\"Return the feature importances (the higher, the more important the\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\sklearn\\tree\\tree.py in _validate_X_predict(self=DecisionTreeClassifier(class_weight=None, criter...         random_state=516035225, splitter='best'), X=       Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns], check_input=True)\n    372         return self\n    373 \n    374     def _validate_X_predict(self, X, check_input):\n    375         \"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\n    376         if check_input:\n--> 377             X = check_array(X, dtype=DTYPE, accept_sparse=\"csr\")\n        X =        Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns]\n    378             if issparse(X) and (X.indices.dtype != np.intc or\n    379                                 X.indptr.dtype != np.intc):\n    380                 raise ValueError(\"No support for np.int64 index based \"\n    381                                  \"sparse matrices\")\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\sklearn\\utils\\validation.py in check_array(array=       Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns], accept_sparse='csr', accept_large_sparse=True, dtype=<class 'numpy.float32'>, order=None, copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)\n    522         # thereby passing the test made in the lines following the scope\n    523         # of warnings context manager.\n    524         with warnings.catch_warnings():\n    525             try:\n    526                 warnings.simplefilter('error', ComplexWarning)\n--> 527                 array = np.asarray(array, dtype=dtype, order=order)\n        array =        Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns]\n        dtype = <class 'numpy.float32'>\n        order = None\n    528             except ComplexWarning:\n    529                 raise ValueError(\"Complex data not supported\\n\"\n    530                                  \"{}\\n\".format(array))\n    531 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\numpy\\core\\numeric.py in asarray(a=       Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns], dtype=<class 'numpy.float32'>, order=None)\n    533     False\n    534     >>> np.asanyarray(a) is a\n    535     True\n    536 \n    537     \"\"\"\n--> 538     return array(a, dtype, copy=False, order=order)\n        a =        Age     AgeGroup        Cabin CabinType  ... 0                4579  \n\n[178 rows x 15 columns]\n        dtype = <class 'numpy.float32'>\n        order = None\n    539 \n    540 \n    541 @set_module('numpy')\n    542 def asanyarray(a, dtype=None, order=None):\n\nValueError: could not convert string to float: '(20, 60]'\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "ensemble.fit(dataProc.X_train.reindex(columns=sortedCols), dataProc.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Random Forest and XGB 0.809 \n"
     ]
    }
   ],
   "source": [
    "y_test_stacking_pred = ensemble.predict(dataProc.X_test.reindex(columns=sortedCols))\n",
    "print('Stacking Random Forest and XGB %.3f ' % accuracy_score(dataProc.y_test, y_test_stacking_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Output/submit.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-fc9c7a17f2e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msubmitDataProc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAllData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mensemble\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubmitDataProc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msortedCols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msubmitDataProc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAllData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'PassengerId'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Survived'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Output/submit.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   3018\u001b[0m                                  \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3019\u001b[0m                                  escapechar=escapechar, decimal=decimal)\n\u001b[1;32m-> 3020\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3021\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3022\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    155\u001b[0m             f, handles = _get_handle(self.path_or_buf, self.mode,\n\u001b[0;32m    156\u001b[0m                                      \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m                                      compression=self.compression)\n\u001b[0m\u001b[0;32m    158\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflowGPU\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m             \u001b[1;31m# Python 3 and encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 424\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    425\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m             \u001b[1;31m# Python 3 and no explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Output/submit.txt'"
     ]
    }
   ],
   "source": [
    "submitDataProc.AllData[target] =  ensemble.predict(submitDataProc.X.reindex(columns=sortedCols))\n",
    "submitDataProc.AllData[['PassengerId', 'Survived']].to_csv('Output/submit.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
